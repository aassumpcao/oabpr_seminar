{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: Utilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar os pacotes necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar os pacotes necessários para fazer análise\n",
    "import pandas as pd, numpy as np\n",
    "import os, re\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir funções para processar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir função que baixa os dados\n",
    "def baixar_tse():\n",
    "    URL = 'http://agencia.tse.jus.br/estatistica/sead/odsele/motivo_cassacao/motivo_cassacao_2016.zip'\n",
    "    r = requests.get(URL)\n",
    "    with open('../dados/motivo_cassacao2016.zip', 'wb') as arquivo:\n",
    "        arquivo.write(r.content)\n",
    "    return 'Motivo(s) para Indeferimento 2016 baixado(s) com sucesso.'\n",
    "\n",
    "# definir função de descomprime arquivo do tse\n",
    "def unzip_tse():\n",
    "    with zipfile.ZipFile('../dados/motivo_cassacao2016.zip', 'r') as zip:\n",
    "        zip.extractall('../dados')\n",
    "    return 'Arquivo(s) descomprimido(s) com sucesso.'\n",
    "\n",
    "# definir função para juntar os dados do tse\n",
    "def juntar_tse():\n",
    "    regex = re.compile(r'motivo.*csv$')\n",
    "    juntar_tse.kwargs = {\n",
    "        'engine': 'python', 'encoding': 'latin1', 'sep':';', 'quoting': 1,\n",
    "        'dtype': str\n",
    "    }\n",
    "    arquivos = os.listdir('../dados')\n",
    "    arquivos = list(filter(regex.search, arquivos))\n",
    "    arquivos = [\n",
    "        os.path.join(os.path.realpath('../dados'), arquivo) \\\n",
    "        for arquivo in arquivos\n",
    "    ]\n",
    "    dados = pd.concat(\n",
    "        [pd.read_csv(arquivo, **juntar_tse.kwargs) for arquivo in arquivos],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    dados = dados[dados['DS_MOTIVO_CASSACAO'].notna()]\n",
    "    print('Arquivo(s) juntado(s) com sucesso.')\n",
    "    return dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executar funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executar função\n",
    "# baixar_tse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executar função\n",
    "unzip_tse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executar função e salvar o resultado no banco de dados chamado \"candidaturas\"\n",
    "candidaturas = juntar_tse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exibir dados preliminares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar os dados\n",
    "candidaturas.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar os motivos para cassação\n",
    "list(candidaturas['DS_MOTIVO_CASSACAO'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focar no Paraná"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focar em 10 candidatos no paraná\n",
    "amostra_pr = candidaturas[candidaturas['SG_UF'] == 'PR'].sample(10, random_state=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar quais informações nós obtivemos\n",
    "amostra_pr.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juntar os motivos de cassação com outros dados dos candidatos?\n",
    "candidatos_pr = pd.read_csv('../dados/consulta_cand_2016_PR.csv', **juntar_tse.kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puxar os números do protocolo da candidatura\n",
    "amostra_pr = amostra_pr.merge(candidatos_pr, on='SQ_CANDIDATO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disponibilizar na tela os números dos protocolos de candidatura\n",
    "# amostra_pr.columns\n",
    "amostra_pr[['NM_CANDIDATO', 'NM_UE_x', 'DS_CARGO', 'NR_PROTOCOLO_CANDIDATURA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar link para raspar documentos\n",
    "links = [\n",
    "    f'http://inter03.tse.jus.br/sadpPush/ExibirDadosProcesso.do?' \\\n",
    "    f'nprot={nprot}&comboTribunal=pr' \\\n",
    "    for nprot in amostra_pr['NR_PROTOCOLO_CANDIDATURA'].to_list()\n",
    "]\n",
    "\n",
    "# disponibilizar os links para a gente\n",
    "for link in links: \n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baixar e processar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar módulo externo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar meu pacote de análise\n",
    "from tse import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construir path para os arquivos\n",
    "decisões = [f'../dados/decisão_{i}.html' for i in range(0, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir função para transformar os dados do sumário em tabela\n",
    "def tabelar_sumário(decisão, transpor=True):\n",
    "    sumário = pd.DataFrame(parser(decisão).parse_summary())\n",
    "    if transpor: \n",
    "        sumário = sumário.T\n",
    "    return sumário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produzir tabela\n",
    "tabelar_sumário(decisões[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar banco de dados\n",
    "sumários = pd.concat([tabelar_sumário(decisão, False) for decisão in decisões], ignore_index=True)\n",
    "sumários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onde estão estes processos? nas seguintes zonas eleitorais\n",
    "sumários['district']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Processamento de Linguagem Natural (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# criar ferramentas de análise de texto\n",
    "nlp_en = spacy.load('en_core_web_sm')\n",
    "nlp_pt = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo Genérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir função que baixa uma reportagem de jornal\n",
    "def baixar_reportagem():\n",
    "    URL = 'https://www.nytimes.com/2020/05/12/well/family/coronavirus-children-covid-19.html'\n",
    "    r = requests.get(URL)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    text = soup.find('section', attrs={'name': 'articleBody'}).get_text()\n",
    "    text = re.sub(r'(”|“)(?![A-z])', r'\\1 ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baixar reportagem do NYTimes\n",
    "baixar_reportagem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar texto\n",
    "texto = baixar_reportagem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processar o texto\n",
    "doc_en = nlp_en(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contar o número de frases\n",
    "frases = list(doc_en.sents)\n",
    "len(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar uma frase qualquer\n",
    "frases[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir função para investigar o conteúdo de uma frase\n",
    "def investigar_frase(frase):\n",
    "    resultado = [{'token': ent.text, 'tipo': ent.label_ , 'descrição': spacy.explain(ent.label_)} for ent in frase.ents]\n",
    "    return pd.DataFrame(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testar reconhecimento do texto\n",
    "print(f'{frases[13]}\\n\\n{investigar_frase(frases[13])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testar reconhecimento do texto\n",
    "print(f'{frases[43]}\\n\\n{investigar_frase(frases[43])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir uma coletânea de decisões judiciais dentre todas\n",
    "decisão = pd.DataFrame(parser(decisões[1]).parse_details())\n",
    "decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrair texto da decisão\n",
    "texto = decisão.loc[3, 'sbody']\n",
    "texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar as entidades reconhecidas pelo software nos autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processar o texto \n",
    "doc_pt = nlp_pt(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar em frases\n",
    "frases = list(doc_pt.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimir as entidades reconhecidas pela nossa ferramenta\n",
    "pd.concat([pd.DataFrame(investigar_frase(frase)) for frase in frases])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Sintática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer análise sintática do texto\n",
    "frase = str(frases[-3])\n",
    "frase = nlp_pt(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpretar a frase mais detalhadamente\n",
    "pd.DataFrame([\n",
    "    {'token': token.text, 'classe gramatical': token.pos_, 'descrição': spacy.explain(token.pos_)}\n",
    "    for token in frase\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.displacy.render(frase, jupyter=True, style='dep', options={'compact': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destacar as entidades no texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrar as entidades na frase\n",
    "colors = {'ORG': 'linear-gradient(90deg, #aa9cfc, #fc9ce7)'}\n",
    "options = {'ents': 'ORG', 'colors': colors}\n",
    "spacy.displacy.render(frase, jupyter=True, style='ent', options=options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
